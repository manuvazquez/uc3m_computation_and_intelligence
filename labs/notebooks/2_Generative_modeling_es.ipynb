{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d8201b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "> Modelado generativo\n",
    "\n",
    "En este *notebook*, vamos a utilizar un autocodificador variacional o VAE (del inglés, [Variational Autoencoder](https://en.wikipedia.org/wiki/Variational_autoencoder)) como una especie de \"máquina para esbozar caras\". El *codificador* aprende a comprimir cada imagen en solo unas pocas variables *latentes* (un boceto aproximado que captura las características principales pero no los detalles) y el *decodificador* aprende a convertir ese boceto de nuevo en una imagen completa. Vamos a forzar a que este \"espacio comprimido\" sigua una distribución [gaussiana](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal) estándar (una \"nube\" de puntos), para así saber qué tipo de variables latentes son válidas. Esa es la parte interesante: como este espacio es suave, los puntos cercanos corresponden a caras similares, y podemos muestrear puntos aleatorios de esta nube gaussiana para generar nuevas caras que el modelo nunca ha visto antes. La imagen de abajo intenta transmitir la idea principal (observa que a la izquierda tenemos un espacio 3D, mientras que el de la derecha es 2D).\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://raw.githubusercontent.com/manuvazquez/uc3m_computation_and_intelligence/master/labs/notebooks/figures/vae.svg\" alt=\"Description\" width=\"1200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6188fe4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "En principio, podrías ejecutar el *notebook* tanto en *Colab* como localmente. ¿Se está ejecutando el *notebook* en *Colab*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    running_in_colab = True\n",
    "except ImportError:\n",
    "    running_in_colab = False\n",
    "\n",
    "running_in_colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac73cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Si ejecutamos el *notebook* en *Colab* necesitamos instalar un par de librerías de Python. Si no, podríamos elegir una GPU si hay varias disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if running_in_colab:\n",
    "    !pip install equinox numpyro\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42cbec9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "El resto de `import`s necesarios van aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44002f-d6e8-4a96-8066-f755b50de837",
   "metadata": {
    "id": "6eQChN-ouFDl"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from jaxtyping import Array, Float, Int\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f28c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "En aras de la reproducibilidad, fijamos las *semillas* aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a542b24",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Dispositivo a usar...deberías ver *[CudaDevice(id=0)]* o similar (siendo el prefijo *Cuda* lo importante) si quieres (deberías) usar la GPU disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173f5f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "En este *notebook* usaremos las librerías [JAX](https://docs.jax.dev/en/latest/) y [Equinox](https://docs.kidger.site/equinox/), que adoptan un enfoque más [funcional](https://es.wikipedia.org/wiki/Programaci%C3%B3n_funcional) para la computación. *PyTorch* solo se usa para el manejo de datos.\n",
    "\n",
    "# Datos\n",
    "\n",
    "Se descargan imágenes del [CelebFaces Dataset](https://www.kaggle.com/datasets/arnrob/celeba-small-images-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = pathlib.Path(kagglehub.dataset_download(\"arnrob/celeba-small-images-dataset\"))\n",
    "print(\"Path to dataset files:\", imgs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0a856",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Algo de código para preparar las imágenes para el entrenamiento. Esencialmente, necesitamos construir un `DataLoader` de *PyTorch* a partir de las imágenes en el directorio de arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2d7a9-a0c6-4451-ad58-2d2b01ccebfa",
   "metadata": {
    "executionInfo": {
     "elapsed": 1239,
     "status": "ok",
     "timestamp": 1620743812042,
     "user": {
      "displayName": "AURORA COBO AGUILERA",
      "photoUrl": "",
      "userId": "02417368943911432830"
     },
     "user_tz": -120
    },
    "id": "mMf8KN88uFDm"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, transform=None, n_samples=None):\n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "\n",
    "        # the names of *all* image files\n",
    "        print(f\"Scanning directory: {img_dir}\")\n",
    "        all_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "        # optionally limit the number of samples and shuffle for randomness\n",
    "        if n_samples is not None and n_samples < len(all_files):\n",
    "            self.image_files = random.sample(all_files, n_samples)\n",
    "        else:\n",
    "            self.image_files = all_files\n",
    "            random.shuffle(self.image_files) # Shuffle if using all files\n",
    "\n",
    "        # we don't have *actual* labels, but in the usual `Dataset` one is expected; it is set to 0 (dummy label) for all images\n",
    "        self.labels = [0] * len(self.image_files)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "def get_celeba(\n",
    "        batch_size: int,\n",
    "        dataset_directory: str | pathlib.Path,\n",
    "        n: int | None = None,\n",
    "        data_subset: str = \"training\", # either 'training' or 'validation'\n",
    "    ) -> torch.utils.data.DataLoader:\n",
    "\n",
    "    # size of the images after resizing\n",
    "    img_size: tuple[int, int] = (64, 64)\n",
    "\n",
    "    train_transformation = transforms.Compose([\n",
    "        transforms.Resize(img_size), # *images* are resized,...\n",
    "        transforms.ToTensor(), # ...converted to *tensors*,...\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # ...and normalized to have values in [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # the path to the specific data subset (e.g., 'training')\n",
    "    actual_image_directory = pathlib.Path(dataset_directory) / data_subset\n",
    "    \n",
    "    if not actual_image_directory.is_dir():\n",
    "        raise ValueError(f\"Specified data_subset '{data_subset}' not found in '{dataset_directory}'.\")\n",
    "\n",
    "    train_dataset = CustomImageDataset(actual_image_directory, train_transformation, n_samples=n)\n",
    "\n",
    "    # a `DataLoader` is returned\n",
    "    return torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc75f4",
   "metadata": {
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Creemos un `DataLoader` que recorra $10,000$ imágenes en batches de tamaño $32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea1951-fbb7-4be3-8ef8-1c8903cb46ad",
   "metadata": {
    "executionInfo": {
     "elapsed": 2033,
     "status": "ok",
     "timestamp": 1620743815085,
     "user": {
      "displayName": "AURORA COBO AGUILERA",
      "photoUrl": "",
      "userId": "02417368943911432830"
     },
     "user_tz": -120
    },
    "id": "t2RvRmKSuFDm"
   },
   "outputs": [],
   "source": [
    "trainloader = get_celeba(32, imgs_dir, n=10_000)\n",
    "trainloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d60d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Un `DataLoader` de *PyTorch* es en última instancia un iterador...\n",
    "\n",
    "<font color='red'>TO-DO</font>: Obtén el primer elemento de él. ¿Qué es?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8815c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b00d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: Extrae la primera imagen del `DataLoader` de arriba. ¿de qué tipo (Python) es?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3045906",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "$d_x$ en la imagen de arriba sería aquí el número total de píxeles en una imagen, es decir, *ancho* $\\times$ *alto* $\\times$ 3 canales (RGB)\n",
    "\n",
    "Vamos a implementar una función para mostrar un `Tensor` de *PyTorch* como imagen. Observa que la función `transforms.Normalize` de arriba está haciendo $\\frac{x - 0.5}{0.5} = 2(x-0.5)$...que debe deshacerse para obtener una imagen lista para \"consumo humano\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa878b7-ea84-42fe-99ca-aa7ab553db3a",
   "metadata": {
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1620743825129,
     "user": {
      "displayName": "AURORA COBO AGUILERA",
      "photoUrl": "",
      "userId": "02417368943911432830"
     },
     "user_tz": -120
    },
    "id": "a-iwMzzmuFDm"
   },
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    \n",
    "    # image is \"unnormalized\"\n",
    "    img = img / 2 + 0.5\n",
    "    \n",
    "    # pytorch expects the channel dimension first whereas matplotlib expects it last\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ec08e",
   "metadata": {
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: Muestra la imagen que has extraido arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f879523-bbce-4fbd-b587-86245f96e116",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 17929,
     "status": "ok",
     "timestamp": 1620743844633,
     "user": {
      "displayName": "AURORA COBO AGUILERA",
      "photoUrl": "",
      "userId": "02417368943911432830"
     },
     "user_tz": -120
    },
    "id": "JwPRmrBMuFDo",
    "outputId": "f1fe85c8-2fc5-4fea-8d59-75d8432a7875"
   },
   "outputs": [],
   "source": [
    "# show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8308c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: ¿Qué pasa si omites la parte de *desnormalización* en `show_image`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f7f25",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "*PyTorch* tiene una función de para \"pegar\" juntas un conjunto de imágenes. Podemos usarla para mostrar un *batch* completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d114b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(torchvision.utils.make_grid(next(iter(trainloader))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb26271",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "# Modelo\n",
    "\n",
    "El modelo engloba dos componentes, el *encoder/compresor* (implementando la función `f_enc` en la imagen de arriba) y el *decoder/descompresor* (implementando la función `f_dec`). En medio de ellos tenemos el \"espacio comprimido\", conocido como el espacio *latente*. Podemos elegir su dimensión (tamaño)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca7e98-954f-4239-afbc-bdc9f9d06a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f21e9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "## Codificador\n",
    "\n",
    "Una clase que define la arquitectura del *encoder* (es decir, el compresor). Esto asume imágenes de $64 \\times 64$. Si tuvieran otro tamaño, habría que hacer ajustes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae318b0f-dc69-4161-af54-1b91a5308cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(eqx.Module):\n",
    "\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, d_z: int, input_channels: int = 3, rng_key: jr.PRNGKey = jr.PRNGKey(42)):\n",
    "\n",
    "        key1, key2, key3, key4, key5, key6 = jr.split(rng_key, 6)\n",
    "\n",
    "        self.layers = [\n",
    "            eqx.nn.Conv2d(in_channels=input_channels, out_channels=32, kernel_size=4, stride=2, padding=1, key=key1),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=1, key=key2),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1, key=key3),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1, key=key4),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Conv2d(in_channels=64, out_channels=256, kernel_size=4, stride=1, padding=0, key=key5),\n",
    "            jnp.ravel,\n",
    "            eqx.nn.Linear(256, 2*d_z, key=key6),\n",
    "            lambda x: x.at[d_z:].set(jax.nn.softplus(x[d_z:]))\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fcaa17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Lo instanciamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55097455-1892-43cf-b0e8-9acbd6156a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(d_z=d_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c927d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "El objeto `encoder` se comporta en última instancia como una función que acepta una imagen (en forma de un array) como entrada, y devuelve un vector de tamaño $2 \\times d_z$ que proporciona la media y desviación típica (apiladas verticalmente) de una distribución gaussiana en el espacio latente. Efectivamente, el encoder no solo te da un $z$ en el espacio comprimido, sino también una medida de su incertidumbre.\n",
    "\n",
    "Lo aplicamos sobre la primera imagen del primer *batch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4abe8-64ad-4805-9f83-7cb9ad709428",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean_std = encoder(next(iter(trainloader))[0][0].numpy())\n",
    "z_mean, z_std = jnp.split(z_mean_std, 2)\n",
    "z_mean, z_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a7e91",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Observa que, como debe ser, las desviaciones típicas son no-negativas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aac396",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "## Decodificador\n",
    "\n",
    "La arquitectura para el *decoder*, es decir, el descompresor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626a373-bdc2-4ee3-b09c-708e44f137b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(eqx.Module):\n",
    "\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, d_z: int, input_channels: int = 3, rng_key: jr.PRNGKey = jr.PRNGKey(42)):\n",
    "\n",
    "        key1, key2, key3, key4, key5, key6 = jr.split(rng_key, 6)\n",
    "\n",
    "        self.layers = [\n",
    "            eqx.nn.Linear(d_z, 256, key=key1),\n",
    "            lambda x: jnp.reshape(x, (256, 1, 1)),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.ConvTranspose2d(in_channels=256, out_channels=64, kernel_size=4, stride=1, padding=0, key=key2),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1, key=key3),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=4, stride=2, padding=1, key=key4),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=1, key=key5),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.ConvTranspose2d(in_channels=32, out_channels=input_channels, kernel_size=4, stride=2, padding=1, key=key6),\n",
    "            jax.nn.tanh\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3074ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "`decoder` se comporta como una función que actúa sobre vectores en el espacio latente (de dimensión $d_z$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a489dd3-9dea-4c0e-96d0-ee1218dd995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(d_z=d_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87236a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Vamos a obtener una muestra a partir de la media y desviación estándar de arriba (en este paradigma de programación *funcional*, debemos pasar una clave/seed de generador de números pseudoaleatorios, aquí `jr.PRNGKey(42)` cada vez que queramos generar un número aleatorio)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef65385",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = dist.Normal(loc=z_mean, scale=z_std).sample(jr.PRNGKey(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6820e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "...y *decodificarla* para (¿quizás?) recuperar la imagen original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccc9b4-db7d-4db4-afb8-f591549a766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_est = decoder(z)\n",
    "x_est.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96a298",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: Visualiza la imagen. ¿Cuál es el problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fe907",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "# Entrenamiento\n",
    "\n",
    "Algunos hiperparámetros que se pueden ajustar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f49146-5486-4378-917d-000a1559958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "# n_epochs = 40\n",
    "n_epochs = 10\n",
    "d_z = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e9cba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Las redes neuronales para el decoder y encoder se instancian *e* inicializan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a0bd6-a933-4f1f-9e8e-671a9dc12302",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(d_z=d_z)\n",
    "decoder = Decoder(d_z=d_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb649a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Por conveniencia, reuniremos ambas cosas en una `tuple` de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6bd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1c892",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Definimos la función de pérdida (la que se debe minimizar). Antes de eso, y por claridad, también definimos la [divergencia de Kullback-Leibler](https://es.wikipedia.org/wiki/Divergencia_de_Kullback-Leibler), que nos da una forma de cuantificar como de diferentes son dos distribuciones de probabilidad. **Ignora** este código por ahora (en este curso), ya que tiene que ver con la teoría matemática en la que se basa un VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd732561-c82d-4d25-813c-f5ff27da4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_loss(mean: Float[Array, 'feature'], sd: Float[Array, 'feature']) -> Float[Array, '']:\n",
    "\n",
    "    return -0.5 * jnp.sum(1 + 2*jnp.log(sd) - mean**2 - sd**2)\n",
    "\n",
    "def loss(model, x: Float[Array, 'batch channel width height'], rng_key) -> Float[Array, '']:\n",
    "\n",
    "    # never mind for now...but this is variance assumed for the decoded `x`\n",
    "    x_var = 0.1\n",
    "\n",
    "    encoder, decoder = model\n",
    "    z_mean_std = jax.vmap(encoder)(x)\n",
    "\n",
    "    z = dist.Normal(loc=z_mean_std[:, :d_z], scale=z_mean_std[:, d_z:]).sample(rng_key)\n",
    "    \n",
    "    x_pred = jax.vmap(decoder)(z)\n",
    "\n",
    "    log_likelihood = dist.Normal(loc=x_pred, scale=jnp.sqrt(x_var)).log_prob(x).sum()\n",
    "\n",
    "    kl_divergence = jax.vmap(kl_loss)(z_mean_std[:, :d_z], z_mean_std[:, d_z:]).sum()\n",
    "    \n",
    "    return -log_likelihood + kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf75890",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "La función de pérdida no es más que una...función, a la que puedes llamar como cualquier otra función. Obtengamos un *batch* de imágenes del `DataLoader` de arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53720ba5-8ffb-4247-bbe6-90505b0cc807",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(iter(trainloader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a202e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: Explica el tamaño del `Tensor` de arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e756a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: Llama a la función de pérdida (con el modelo de arriba) sobre las imágenes. A la vista de la definición, la función `loss` recibe:\n",
    "\n",
    "- el modelo,\n",
    "\n",
    "- un array de *numpy* o de *JAX*, por lo que debes convertir `images`, que es un tensor de *PyTorch* (puedes usar el método `numpy()` sobre `images`)\n",
    "\n",
    "- una clave de generador de números pseudoaleatorios (puedes usar de nuevo `jr.PRNGKey(42)`...u otra cosa) para producir los números aleatorios necesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f01ffa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Una ventaja de *JAX*/*Equinox* es que si tienes una función (de Python), puedes obtener fácilmente el [gradiente](https://es.wikipedia.org/wiki/Gradiente) de esa función usando `jax.grad`. En este caso, como estamos usando *Equinox*, llamamos al *wrapper* equivalente `eqx.filter_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_loss = eqx.filter_grad(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7fd75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Ahora, `grad_loss` es una función que recibe los mismos argumentos que `loss`, así que puedes...\n",
    "\n",
    "<font color='red'>TO-DO</font>: ...llamar a la función tal como llamas a `loss` arriba. ¿Qué resulta? Ten en cuenta que estamos calculando el *gradiente* de la función de pérdida!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eec0ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Empaquetatamos en una única función todas las operaciones que hay que hacer sobre cada *batch* durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7891c06-2f94-4a14-a18b-ed23561b24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def take_step(model, opt_state, x: jax.Array, rng_key):\n",
    "\n",
    "    loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, rng_key)\n",
    "\n",
    "    updates, opt_state = optim.update(grads, opt_state, model)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    \n",
    "    return model, opt_state, loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d392b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "## Bucle\n",
    "\n",
    "Vamos a implementar el bucle de entrenamiento. Verás que la evolución de la *pérdida* es ruidosa: es de esperar. Además, la primera iteración podría tardar un poco (ya que los datos se están leyendo en memoria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330b7da-e59e-4fc0-97eb-707e501b4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optax.adam(learning_rate)\n",
    "opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "key = jr.PRNGKey(42)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    key, subkey = jr.split(key)\n",
    "\n",
    "    for x, _ in trainloader:\n",
    "\n",
    "        model, opt_state, loss_value = take_step(model, opt_state, x.numpy(), subkey)\n",
    "\n",
    "    print(epoch, loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1040251",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "# Resultados\n",
    "\n",
    "Veamos la primera imagen en el último *batch* procesado en el bucle de entrenamiento (todavía en `x`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f869323-3c22-42e3-89e9-5a85f4ca0752",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536523e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "Codifiquémosla en el espacio latente y decodifiquémosla de vuelta. Formalmente, el codificador devuelve la media y desviación típica (apiladas) en el espacio de datos pero, por simplicidad, podemos tomar la media como si fuera una muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19e3b4-ea28-4cca-a5d3-493cf6e00e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = model\n",
    "show_image(decoder(encoder(x[0].numpy())[:d_z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1bbccc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "# Experimentos\n",
    "\n",
    "<font color='red'>TO-DO</font>: Genera un par de imágenes nuevas extrayendo muestras en el *espacio latente* y llamando al decoder sobre ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d752c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: Entrena durante más *epochs* para intentar mejorar la calidad de las *reconstrucciones*. ¿Mejora?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d067330",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: Entrena con muy pocas imágenes, digamos 10. El número de imágenes que usas para entrenar (del número total que hay en el conjunto de datos) está controlado por el parámetro `n` de la función `get_celeba` arriba. Usa un número mucho mayor de epochs, digamos 500, o el modelo no habrá visto suficientes ejemplos para aprender algo. Luego, genera unas pocas imágenes y compáralas. ¿Qué observas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f61b60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "<font color='red'>TO-DO</font>: Experimenta con la dimensión del espacio latente. ¿Puedes obtener buenos resultados con una dimensión pequeña, digamos $d_z=10$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c06b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "spanish"
    ]
   },
   "source": [
    "# Preguntas de muestra\n",
    "\n",
    "## ¿Qué ocurre típicamente cuando usas una dimensión del espacio latente *más pequeña* (por ejemplo, 10)?\n",
    "- [ ] El modelo siempre entrena más rápido y se vuelve perfecto\n",
    "- [ ] El modelo tiene menos capacidad para capturar detalles, por lo que las reconstrucciones pueden volverse más borrosas o perder información\n",
    "- [ ] El modelo deja de usar la red decoder\n",
    "- [ ] El modelo no puede entrenarse en absoluto\n",
    "\n",
    "## ¿Por qué establecemos semillas aleatorias (para, por ejemplo, *numpy* o *PyTorch*) al principio?\n",
    "- [ ] Para hacer que el entrenamiento se ejecute solo una vez\n",
    "- [ ] Para evitar usar la GPU por error\n",
    "- [ ] Para hacer los resultados más reproducibles cuando ejecutamos el código de nuevo\n",
    "- [ ] Para evitar que el código use cualquier número aleatorio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
